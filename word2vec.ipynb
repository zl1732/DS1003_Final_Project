{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec context nearest neighbour model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#package to load word2vec vectors\n",
    "import gensim\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "#self built functions\n",
    "import utilities\n",
    "#semcor corpus\n",
    "import nltk\n",
    "from nltk.corpus import semcor\n",
    "from nltk.corpus import wordnet as wn\n",
    "#Micellaneous\n",
    "import numpy as np\n",
    "import collections\n",
    "from scipy.spatial.distance import cosine\n",
    "import sys\n",
    "import re\n",
    "import time\n",
    "import progressbar\n",
    "import pickle\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load word2vec binary file\n",
    "model = KeyedVectors.load_word2vec_format('../datasets/word2vec/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "#Define embedding_dict\n",
    "embedding_dict = model.word_vec\n",
    "#Load semcor\n",
    "tagged_chunks = semcor.tagged_chunks(tag='sem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#prediction method\n",
    "def predict(context,predict_lemmas):\n",
    "    #senses_choices must be a python list of sense label (wordnet synset)\n",
    "    #get context embedding\n",
    "    context_emb = getContextEmb_word2vec(context=context,emb_size=300,embedding_dict=embedding_dict)\n",
    "    #get senses choice\n",
    "    synsets = wn.synsets(predict_lemmas)\n",
    "    senses_choices = [synset.name() for synset in synsets]\n",
    "    #calculate cosine distance between each sense and context\n",
    "    decision_chart = [[choice,cosine(context_emb,sense_embeddings[choice])] for choice in senses_choices]\n",
    "    prediction = sorted(decision_chart,key=lambda x:x[1])[0][0]\n",
    "    return prediction\n",
    "def get_context(tagged_chunks,position,window_size):\n",
    "    center = tagged_chunks[position].leaves()\n",
    "    num_words = 0\n",
    "    iter_position = position\n",
    "    #unroll left size\n",
    "    left = []\n",
    "    right = []\n",
    "    while (num_words<window_size):\n",
    "        iter_position-=1\n",
    "        if iter_position <0:\n",
    "            break\n",
    "        item = tagged_chunks[iter_position]\n",
    "        if type(item)==list:\n",
    "            num_words +=1\n",
    "            left.insert(0,item[0])\n",
    "        elif type(item)==nltk.tree.Tree:\n",
    "            words2append = item.leaves()\n",
    "            if num_words+len(words2append)>window_size:\n",
    "                num_allowed = window_size-num_words\n",
    "                words2append=words2append[-num_allowed:]\n",
    "            num_words += len(words2append)\n",
    "            left = words2append+left\n",
    "            \n",
    "    num_words = 0\n",
    "    iter_position = position\n",
    "    while (num_words<window_size):\n",
    "        iter_position+=1\n",
    "        if iter_position >=len(tagged_chunks):\n",
    "            break\n",
    "        item = tagged_chunks[iter_position]\n",
    "        if type(item)==list:\n",
    "            num_words +=1\n",
    "            right.append(item[0])\n",
    "        elif type(item)==nltk.tree.Tree:\n",
    "            words2append = item.leaves()\n",
    "            if num_words+len(words2append)>window_size:\n",
    "                num_allowed = window_size-num_words\n",
    "                words2append=words2append[:num_allowed]\n",
    "            num_words += len(words2append)\n",
    "            right = right+words2append\n",
    "    return left+center+right\n",
    "\n",
    "def getContextEmb_word2vec(context,embedding_dict,emb_size,unk_emb=np.zeros(300)):\n",
    "    # Input introductions\n",
    "    # sentence: an array of tokens of untagged sentence. \n",
    "    # center: position of the center word\n",
    "    # window_size: size of context window\n",
    "    # embedding_Dict: gensim model method\n",
    "    ################################################################\n",
    "        output_embedding = np.zeros(emb_size)\n",
    "        for word in context:\n",
    "            try:\n",
    "                output_embedding+=embedding_dict(word)#use gensim model method\n",
    "            except:\n",
    "                output_embedding+=unk_emb\n",
    "        return output_embedding\n",
    "    \n",
    "def buildSemEmb_word2vec(tagged_chunks,embedding_dict,emb_size=300,window_size=4):\n",
    "    progress = progressbar.ProgressBar(max_value=len(tagged_chunks))\n",
    "    output_dict = collections.defaultdict(partial(np.zeros,emb_size))\n",
    "    for idx in range(len(tagged_chunks)):\n",
    "        progress.update(idx)\n",
    "        itm=tagged_chunks[idx]\n",
    "        if(type(itm))==list:\n",
    "            continue\n",
    "        else:\n",
    "            #Use try except handling since some of the label is broken\n",
    "            try:\n",
    "                sense_index = itm.label().synset().name()\n",
    "            except:\n",
    "                continue\n",
    "            context = get_context(position=idx,tagged_chunks=tagged_chunks,window_size=window_size)\n",
    "            context_emb = getContextEmb_word2vec(context,embedding_dict=embedding_dict,emb_size=300)\n",
    "            output_dict[sense_index]+=context_emb\n",
    "    return output_dict\n",
    "def buildSemEmb_word2vec_gloss(tagged_chunks,embedding_dict,emb_size=300,threshold=0.5):\n",
    "    progress = progressbar.ProgressBar(max_value=len(tagged_chunks))\n",
    "    output_dict = collections.defaultdict(partial(np.ones,emb_size))\n",
    "    for idx in range(len(tagged_chunks)):\n",
    "        progress.update(idx)\n",
    "        itm = tagged_chunks[idx]\n",
    "        if(type(itm))==list:\n",
    "            continue\n",
    "        else:\n",
    "            #Use try except handling since some of the label is broken\n",
    "            try:\n",
    "                sense_synset = itm.label().synset()\n",
    "            except:\n",
    "                continue\n",
    "            if sense_synset.name() in output_dict:\n",
    "                continue\n",
    "            predicted_lemmas_emb = getContextEmb_word2vec(itm.leaves(),embedding_dict,300)\n",
    "            gloss = sense_synset.definition()\n",
    "            closest_gloss_emb_dist = None\n",
    "            closest_gloss_emb = None\n",
    "            gloss_count = 0\n",
    "            for word in gloss:\n",
    "                try:\n",
    "                    word_emb = embedding_dict(word)\n",
    "                except:\n",
    "                    continue\n",
    "                dist = cosine(word_emb,predicted_lemmas_emb)\n",
    "                if closest_gloss_emb_dist==None:\n",
    "                    closest_gloss_emb_dist = dist\n",
    "                    closest_gloss_emb = word_emb\n",
    "                if dist<closest_gloss_emb_dist:\n",
    "                    closest_gloss_emb_dist  = dist\n",
    "                    closest_gloss_emb = word_emb\n",
    "                if dist<threshold:\n",
    "                    gloss_count+=1\n",
    "                    output_dict[sense_synset.name()]+=closest_gloss_emb\n",
    "            if gloss_count==0:\n",
    "                #print(type(closest_gloss_emb))\n",
    "                output_dict[sense_synset.name()]+=closest_gloss_emb\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "N/A% (0 of 778587) |                     | Elapsed Time: 0:00:00 ETA:  --:--:--/Users/zhuorulin/anaconda/envs/py35/lib/python3.5/site-packages/scipy/spatial/distance.py:505: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - np.dot(u, v) / (norm(u) * norm(v))\n",
      " 99% (777825 of 778587) |################# | Elapsed Time: 0:02:45 ETA: 0:00:00"
     ]
    }
   ],
   "source": [
    "sense_embeddings_gloss = buildSemEmb_word2vec_gloss(tagged_chunks,embedding_dict=embedding_dict,emb_size = 300,threshold=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sense_embeddings = sense_embeddings_gloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35493030592145003"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#build sense embeddings\n",
    "#sense_embeddings = buildSemEmb_word2vec(tagged_chunks=tagged_chunks,embedding_dict=embedding_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% (599953 of 600000) |################# | Elapsed Time: 0:15:06 ETA: 0:00:00"
     ]
    }
   ],
   "source": [
    "sense_embeddings_train_win5 = buildSemEmb_word2vec(tagged_chunks=tagged_chunks[:600000],embedding_dict=embedding_dict,window_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% (628564 of 628587) |################# | Elapsed Time: 0:10:50 ETA: 0:00:00"
     ]
    }
   ],
   "source": [
    "sense_embeddings_train2_win5 = buildSemEmb_word2vec(tagged_chunks=tagged_chunks[150000:],embedding_dict=embedding_dict,window_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sense_embeddings_train2_win5' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-9753a072f4ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msense_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msense_embeddings_train2_win5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sense_embeddings_train2_win5' is not defined"
     ]
    }
   ],
   "source": [
    "sense_embeddings = sense_embeddings_train2_win5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('sense_win5.pk','wb')\n",
    "pickle.dump(obj=sense_mebeddings_win5,file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('sense_win5.pk','rb')\n",
    "sense_embeddings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt: trying to classify some ambiguous word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma to predict:(Lemma('probe.n.01.investigation') investigation)\n",
      "context:Grand Jury said Friday an investigation of Atlanta 's recent primary\n",
      "\n",
      "Final decision: probe.n.01\n"
     ]
    }
   ],
   "source": [
    "#Example test\n",
    "example = tagged_chunks[:30]\n",
    "context = get_context(position=5,tagged_chunks=example,window_size=5)\n",
    "print('lemma to predict:%s'%(example[5]))\n",
    "print('context:%s'%(' '.join(context)))\n",
    "senses_choices = example[5]\n",
    "print()\n",
    "print('Final decision: %s'%(predict(context=context,predict_lemmas='investigation')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notice how closed possible senses are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(wn.synsets('investigation')[0])\n",
    "print(wn.synsets('investigation')[0].definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(wn.synsets('investigation')[1])\n",
    "print(wn.synsets('investigation')[1].definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform all-words WSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_all(tagged_chunks,window_size = 4):\n",
    "    progress = progressbar.ProgressBar(max_value=len(tagged_chunks))\n",
    "    num_correct = 0\n",
    "    num_predicted = 0.0\n",
    "    for idx in range(len(tagged_chunks)):\n",
    "        progress.update(idx)\n",
    "        itm=tagged_chunks[idx]\n",
    "        if (idx%100000==0)&(num_predicted>0):\n",
    "            print('correct: %s, predicted: %s, accuracy: %s'%(num_correct,num_predicted,num_correct/num_predicted))\n",
    "        if(type(itm))==list:\n",
    "            continue\n",
    "        else:\n",
    "            #Use try except handling since some of the label is broken\n",
    "            try:\n",
    "                lemma = itm.label().name()\n",
    "            except:\n",
    "                continue\n",
    "            context = get_context(position=idx,tagged_chunks=tagged_chunks,window_size=window_size)\n",
    "            prediction = predict(context=context,predict_lemmas=lemma)\n",
    "            correct = itm.label().synset().name()\n",
    "            num_predicted +=1\n",
    "            if prediction == correct:\n",
    "                num_correct+=1\n",
    "    return num_correct/num_predicted\n",
    "def predict_baseline(tagged_chunks,window_size = 4):\n",
    "    progress = progressbar.ProgressBar(max_value=len(tagged_chunks))\n",
    "    num_correct = 0\n",
    "    num_predicted = 0.0\n",
    "    for idx in range(len(tagged_chunks)):\n",
    "        progress.update(idx)\n",
    "        itm=tagged_chunks[idx]\n",
    "        if (idx%100000==0)&(num_predicted>0):\n",
    "            print('correct: %s, predicted: %s, accuracy: %s'%(num_correct,num_predicted,num_correct/num_predicted))\n",
    "        if(type(itm))==list:\n",
    "            continue\n",
    "        else:\n",
    "            #Use try except handling since some of the label is broken\n",
    "            try:\n",
    "                lemma = itm.label().name()\n",
    "            except:\n",
    "                continue\n",
    "            synsets = wn.synsets(lemma)\n",
    "            senses_choices = [synset.name() for synset in synsets]\n",
    "            prediction = senses_choices[0]\n",
    "            correct = itm.label().synset().name()\n",
    "            num_predicted +=1\n",
    "            if prediction == correct:\n",
    "                num_correct+=1\n",
    "    return num_correct/num_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "778587"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tagged_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% (9993 of 10000) |#################### | Elapsed Time: 0:00:20 ETA: 0:00:00"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.504769805060141"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_all(tagged_chunks=tagged_chunks[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "N/A% (0 of 778587) |                     | Elapsed Time: 0:00:00 ETA:  --:--:--/Users/zhuorulin/anaconda/envs/py35/lib/python3.5/site-packages/scipy/spatial/distance.py:505: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - np.dot(u, v) / (norm(u) * norm(v))\n",
      " 12% (100068 of 778587) |##                | Elapsed Time: 0:04:04 ETA: 0:27:35"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 35611, predicted: 46755.0, accuracy: 0.7616511603037108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25% (200044 of 778587) |####              | Elapsed Time: 0:07:40 ETA: 0:22:11"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 66617, predicted: 90254.0, accuracy: 0.7381057903250825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38% (300078 of 778587) |######            | Elapsed Time: 0:11:49 ETA: 0:18:51"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 99284, predicted: 134788.0, accuracy: 0.7365937620559694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51% (400072 of 778587) |#########         | Elapsed Time: 0:15:36 ETA: 0:14:40"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 130896, predicted: 178290.0, accuracy: 0.7341746592629985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64% (500421 of 778587) |###########       | Elapsed Time: 0:16:31 ETA: 0:08:50"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 138952, predicted: 193085.0, accuracy: 0.7196416086179662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77% (600628 of 778587) |#############     | Elapsed Time: 0:17:01 ETA: 0:04:41"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 143980, predicted: 203822.0, accuracy: 0.7064006829488475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89% (700597 of 778587) |################  | Elapsed Time: 0:17:32 ETA: 0:01:45"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 149102, predicted: 214747.0, accuracy: 0.6943147052112486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% (778374 of 778587) |################# | Elapsed Time: 0:18:00 ETA: 0:00:00"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6827996226347923"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Window size 4 should get 68.3% accuracy.\n",
    "predict_all(tagged_chunks,window_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56% (101727 of 178587) |##########        | Elapsed Time: 0:00:09 ETA: 0:00:06"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 2295, predicted: 10925.0, accuracy: 0.21006864988558352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% (177854 of 178587) |################# | Elapsed Time: 0:00:16 ETA: 0:00:00"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1977601225232124"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_baseline(tagged_chunks[600000:],window_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sense_embeddings = sense_embeddings_win5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "N/A% (0 of 178587) |                     | Elapsed Time: 0:00:00 ETA:  --:--:--/Users/zhuorulin/anaconda/envs/py35/lib/python3.5/site-packages/scipy/spatial/distance.py:505: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - np.dot(u, v) / (norm(u) * norm(v))\n",
      " 56% (100675 of 178587) |##########        | Elapsed Time: 0:00:32 ETA: 0:00:25"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 5122, predicted: 10925.0, accuracy: 0.46883295194508007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% (178332 of 178587) |################# | Elapsed Time: 0:01:02 ETA: 0:00:00"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4525701158227242"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_all(tagged_chunks[600000:],window_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56% (101727 of 178587) |##########        | Elapsed Time: 0:00:09 ETA: 0:00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 2295, predicted: 10925.0, accuracy: 0.21006864988558352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% (177404 of 178587) |################# | Elapsed Time: 0:00:17 ETA: 0:00:00"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1977601225232124"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_baseline(tagged_chunks[600000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67% (100633 of 150000) |############      | Elapsed Time: 0:00:30 ETA: 0:00:14"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 26806, predicted: 46755.0, accuracy: 0.5733290557159662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% (149842 of 150000) |################# | Elapsed Time: 0:00:43 ETA: 0:00:00"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5670554567922647"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_baseline(tagged_chunks[:150000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "N/A% (0 of 150000) |                     | Elapsed Time: 0:00:00 ETA:  --:--:--/Users/zhuorulin/anaconda/envs/py35/lib/python3.5/site-packages/scipy/spatial/distance.py:505: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - np.dot(u, v) / (norm(u) * norm(v))\n",
      " 66% (100067 of 150000) |############      | Elapsed Time: 0:04:04 ETA: 0:02:04"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 27789, predicted: 46755.0, accuracy: 0.594353545075393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% (149954 of 150000) |################# | Elapsed Time: 0:05:55 ETA: 0:00:00"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5862348061107979"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_all(tagged_chunks[:150000],window_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
