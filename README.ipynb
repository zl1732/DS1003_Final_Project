{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Sense Disambiguation Knowledge Sources\n",
    "To train an all-word WSD model, several knowledge sources are neccesary. Including :\n",
    "- Sense inventory\n",
    "- Sense labeled corpus\n",
    "- Embeddings\n",
    "\n",
    "Here we explore how to leverage these knowledge sources using Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sense inventory word-net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The powerful NLTK package includes handy wordnet interface. The senses of a word is stored as form of synset, which includes the definition of a sense and words related to this sense.\n",
    "\n",
    "For a more detailed documentation of wordnet interface, please refer to : http://www.nltk.org/howto/wordnet.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get access to all the synsets of a particular word, use wn.synsets(word)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('qualify.v.01'),\n",
       " Synset('qualify.v.02'),\n",
       " Synset('qualify.v.03'),\n",
       " Synset('qualify.v.04'),\n",
       " Synset('stipulate.v.01'),\n",
       " Synset('qualify.v.06'),\n",
       " Synset('modify.v.02')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example. \n",
    "wn.synsets('qualify')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under every synnet, it contains the lemmas that are  in this synnet. use .lemmas() to access them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qualify_.v.03 definition: make more specific\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Lemma('qualify.v.03.qualify'), Lemma('qualify.v.03.restrict')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: Let's choose the third synnet of the word 'qualify', which is not its usual sense.\n",
    "qualify_03 = wn.synsets('qualify')[2]\n",
    "# It is also easy to print out its definition\n",
    "print('qualify_.v.03 definition: %s'%(qualify_03.definition()))\n",
    "qualify_03.lemmas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sense labeled corpus\n",
    "NLTK also contains wordnet's senses labeled corpus: SemCor. For a detail documentation of NTLK tagged corpora please refer to:\n",
    "http://www.nltk.org/howto/corpus.html#tagged-corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import semcor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SemCor corpus is a chunk corpus that consists of tree. The senses taged are associated with each tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The'],\n",
       " Tree(Lemma('group.n.01.group'), [Tree('NE', ['Fulton', 'County', 'Grand', 'Jury'])]),\n",
       " Tree(Lemma('state.v.01.say'), ['said']),\n",
       " Tree(Lemma('friday.n.01.Friday'), ['Friday']),\n",
       " ['an'],\n",
       " Tree(Lemma('probe.n.01.investigation'), ['investigation']),\n",
       " ['of'],\n",
       " Tree(Lemma('atlanta.n.01.Atlanta'), ['Atlanta']),\n",
       " [\"'s\"],\n",
       " Tree(Lemma('late.s.03.recent'), ['recent']),\n",
       " Tree(Lemma('primary.n.01.primary_election'), ['primary', 'election']),\n",
       " Tree(Lemma('produce.v.04.produce'), ['produced']),\n",
       " ['``'],\n",
       " ['no'],\n",
       " Tree(Lemma('evidence.n.01.evidence'), ['evidence']),\n",
       " [\"''\"],\n",
       " ['that'],\n",
       " ['any'],\n",
       " Tree(Lemma('abnormality.n.04.irregularity'), ['irregularities']),\n",
       " Tree(Lemma('happen.v.01.take_place'), ['took', 'place']),\n",
       " ['.']]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_chunk = semcor.tagged_sents(tag='sem')[0]\n",
    "example_chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access the sense of each tree, we need to use the .synset() method of lemma object to access its belonged synset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('group.n.01')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tree = example_chunk[1]\n",
    "example_tree.label().synset()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
