{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import random\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import semcor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "778587"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = semcor.tagged_chunks(tag='both')\n",
    "chunks\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_num = int(778587/5)\n",
    "train_num = 778587 - test_num\n",
    "shuffle = np.random.choice(778587, 778587, replace=False)\n",
    "train_i = shuffle[:train_num]\n",
    "test_i = shuffle[-1*test_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training:  622870\n",
      "testing:  155717\n"
     ]
    }
   ],
   "source": [
    "print(\"training: \",len(train_i))\n",
    "print(\"testing: \", len(test_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## create dictionary for a segment of chunks\n",
    "def count_synset(a,b,index):\n",
    "    list_s = {}\n",
    "    for i in range(a,b):\n",
    "        chunk= chunks[index[i]]\n",
    "        if chunk.label() is not None:\n",
    "            if not isinstance(chunk.label(),str):\n",
    "                ck_categ = chunk.label().synset().name().split(\".\")[0]\n",
    "                ck_name = chunk.label().synset().name()\n",
    "                if ck_categ in list_s:\n",
    "                    if ck_name in list_s[ck_categ]:\n",
    "                        list_s[ck_categ][ck_name] += 1\n",
    "                    else:\n",
    "                        list_s[ck_categ][ck_name] = 1\n",
    "                else:\n",
    "                    list_s[ck_categ] = {}\n",
    "                    list_s[ck_categ][ck_name]=1\n",
    "    return list_s\n",
    "\n",
    "\n",
    "## merge two nested dictionary\n",
    "def merge(d1, d2):\n",
    "    if d1 =={}:\n",
    "        return d2\n",
    "    for k in d2:\n",
    "        if k in d1 and isinstance(d1[k], dict) and isinstance(d2[k], dict):\n",
    "            merge(d1[k], d2[k])\n",
    "        else:\n",
    "            d1[k] = d2[k] \n",
    "    return d1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Train data into dictionary \n",
    "- Count frequency of each sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "63.23213744163513\n",
      "1\n",
      "60.80057191848755\n",
      "2\n",
      "62.392069578170776\n",
      "3\n",
      "68.61357855796814\n",
      "4\n",
      "70.12432432174683\n",
      "5\n",
      "57.63247537612915\n",
      "6\n",
      "58.62727117538452\n",
      "7\n",
      "57.583555459976196\n",
      "8\n",
      "58.0486044883728\n",
      "9\n",
      "61.036747217178345\n",
      "10\n",
      "56.623414516448975\n",
      "11\n",
      "61.312039375305176\n",
      "12\n",
      "57.08102893829346\n",
      "13\n",
      "56.36939597129822\n",
      "14\n",
      "58.090678691864014\n",
      "15\n",
      "65.90428614616394\n",
      "16\n",
      "65.13918542861938\n",
      "17\n",
      "63.127320289611816\n",
      "18\n",
      "59.81525778770447\n",
      "19\n",
      "58.44715118408203\n",
      "20\n",
      "59.30609202384949\n",
      "21\n",
      "59.90309810638428\n",
      "22\n",
      "58.9808611869812\n",
      "23\n",
      "58.640222787857056\n",
      "24\n",
      "58.89990305900574\n",
      "25\n",
      "60.465932846069336\n",
      "26\n",
      "65.40757966041565\n",
      "27\n",
      "58.9290292263031\n",
      "28\n",
      "58.12343978881836\n",
      "29\n",
      "58.579862117767334\n",
      "30\n",
      "60.12271451950073\n",
      "31\n",
      "58.956294298172\n",
      "32\n",
      "62.5788631439209\n",
      "33\n",
      "70.02761888504028\n",
      "34\n",
      "67.63263845443726\n",
      "35\n",
      "61.65708947181702\n",
      "36\n",
      "59.63716173171997\n",
      "37\n",
      "59.11623454093933\n",
      "38\n",
      "59.05408787727356\n",
      "39\n",
      "60.527588844299316\n",
      "40\n",
      "61.336925983428955\n",
      "41\n",
      "61.808279275894165\n",
      "42\n",
      "61.32623028755188\n",
      "43\n",
      "62.14174032211304\n",
      "44\n",
      "71.83173179626465\n",
      "45\n",
      "61.046517848968506\n",
      "46\n",
      "60.77556276321411\n",
      "47\n",
      "64.71693086624146\n",
      "48\n",
      "59.94306230545044\n",
      "49\n",
      "59.47373032569885\n",
      "50\n",
      "62.82616448402405\n",
      "51\n",
      "61.75903868675232\n",
      "52\n",
      "62.46089434623718\n",
      "53\n",
      "59.35672354698181\n",
      "54\n",
      "58.85208582878113\n",
      "55\n",
      "60.21762251853943\n",
      "56\n",
      "71.79008841514587\n",
      "57\n",
      "62.557326793670654\n",
      "58\n",
      "63.23085880279541\n",
      "59\n",
      "65.99935674667358\n",
      "60\n",
      "67.26457715034485\n",
      "61\n",
      "70.80391788482666\n"
     ]
    }
   ],
   "source": [
    "## count senses of first 600,000 chunks, as training data\n",
    "import time\n",
    "result = {}\n",
    "for i in range(62):\n",
    "    start = time.time()\n",
    "    print(i)\n",
    "    segment = count_synset(i*10000,(i+1)*10000,train_i)\n",
    "    result = merge(result,segment)\n",
    "    end = time.time()\n",
    "    print(end-start)\n",
    "segment = count_synset(620000,622869,train_i)\n",
    "result = merge(result,segment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create prediction match for each word and sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## select the sense with max number\n",
    "reduced={}\n",
    "for (k, v) in result.items():\n",
    "    reduced[k] = max(result[k], key=result[k].get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Test Data into dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8765"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## count sense for test\n",
    "test = {}\n",
    "test = count_synset(0,155716,test_i)\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate accuracy for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## calculate accuracy for test data\n",
    "tr, fl, na = 0, 0, 0\n",
    "for k1, v1 in test.items():\n",
    "    for k2, v2 in v1.items():\n",
    "        if k1 in reduced:\n",
    "            if k2 == reduced[k1]:\n",
    "                tr += v2\n",
    "            else:\n",
    "                fl += v2\n",
    "        else:\n",
    "            na += v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29494 14003 1504\n",
      "0.6780697519369152\n"
     ]
    }
   ],
   "source": [
    "print(tr,fl,na)\n",
    "print(tr/(tr+fl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate accuracy for train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## calculate accuracy for train data\n",
    "tr, fl, na = 0, 0, 0\n",
    "for k1, v1 in result.items():\n",
    "    for k2, v2 in v1.items():\n",
    "        if k1 in reduced:\n",
    "            if k2 == reduced[k1]:\n",
    "                tr += v2\n",
    "            else:\n",
    "                fl += v2\n",
    "        else:\n",
    "            na += v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17359 7484 0\n",
      "0.6987481383085778\n"
     ]
    }
   ],
   "source": [
    "print(tr,fl,na)\n",
    "print(tr/(tr+fl))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
