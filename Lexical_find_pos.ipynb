{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "os.chdir(\"C:\\Spring_2017\\machine_learning\\DS1003_Final_Project\")\n",
    "result = pickle.load( open( \"result.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import semcor\n",
    "from utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('enjoy.v.01'), Synset('enjoy.v.02'), Synset('love.v.02'), Synset('enjoy.v.04'), Synset('delight.v.02')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Synset('gusto.n.01'),\n",
       " Synset('relish.n.02'),\n",
       " Synset('relish.n.03'),\n",
       " Synset('enjoy.v.01')]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(wordnet.synsets('enjoy'))\n",
    "wordnet.synset('delight.v.02').definition()\n",
    "wordnet.synset('enjoy.v.01').lemmas()\n",
    "wordnet.synsets('relish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sents_tag_pos = semcor.tagged_sents(tag='pos')\n",
    "sents_tag_cor = semcor.tagged_sents(tag='sem')\n",
    "sents_tag_both = semcor.tagged_sents(tag='semcor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'act': 0.45588235294117646,\n",
       " 'anode': 1.0,\n",
       " 'be': 0.6049149338374291,\n",
       " 'form': 0.7441860465116279,\n",
       " 'have': 0.6261682242990654,\n",
       " 'high': 0.6785714285714286,\n",
       " 'information': 0.9836065573770492,\n",
       " 'not': 1.0,\n",
       " 'person': 1.0,\n",
       " 'play': 0.22950819672131148,\n",
       " 'report': 0.5892857142857143,\n",
       " 'state': 0.5966386554621849,\n",
       " 'stress': 0.9054054054054054,\n",
       " 'sum': 0.7868852459016393,\n",
       " 'use': 0.5662650602409639}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pickle.load( open( \"result.p\", \"rb\" ) )\n",
    "Baseline_acc(result, 15)\n",
    "#m_most_freq(result, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_pos(word):\n",
    "    pos = {}\n",
    "    for i in range(37176):\n",
    "        #len(sents_tag_pos)\n",
    "        #37176\n",
    "        if i%10000==0:\n",
    "            print(i)\n",
    "        try:\n",
    "            pos[i] = [x.label().synset().name().split(\".\")[0] if(len(str(x))>15) else x[0] for x in sents_tag_cor[i]].index(word)\n",
    "        except:\n",
    "            continue\n",
    "    return pos\n",
    "\n",
    "\n",
    "def getContextEmb(pos, window_size):\n",
    "    cor_dict={}\n",
    "    pos_dict={}\n",
    "    tar_dict={}\n",
    "    head_flag=False\n",
    "    tail_flag=False\n",
    "    for idx, center in pos.items():\n",
    "        if idx%100==0:\n",
    "            print(idx)\n",
    "        # idx is the index of sentence that contain the word\n",
    "        # center is the index of word in the sentence\n",
    "        sent_len = len(sents_tag_cor[idx])\n",
    "        start_pos = max([0,center-window_size])\n",
    "        end_pos = min([len(sents_tag_cor[idx]),(center+window_size)+1])\n",
    "        \n",
    "        #cor_dict[idx] = [x.label().synset().name().split('.')[1] if(x.label() \\\n",
    "        #                 is not None and not isinstance(x.label(),str)) \\\n",
    "        #                 else \"None\" if(x.label() is None) \\\n",
    "        #                 else \"NA\" for x in sents_tag_both[idx][start_pos:end_pos]]\n",
    "  \n",
    "        pos_dict[idx] = [x.label() if(x.label() is not None) \\\n",
    "                         else \"None\" for x in sents_tag_pos[idx][start_pos:end_pos]]\n",
    "\n",
    "        if center-window_size<0:\n",
    "            pos_dict[idx] = [\"start\"]*(window_size-center) + pos_dict[idx]\n",
    "                       \n",
    "        if sent_len<(center+window_size)+1:\n",
    "            pos_dict[idx] = pos_dict[idx] + [\"end\"]*((center+window_size)+1-sent_len)\n",
    "              \n",
    "        try:\n",
    "            tar_dict[idx] = sents_tag_both[idx][center].label().synset().name()\n",
    "        except:\n",
    "            tar_dict[idx] = sents_tag_both[idx][center].label()\n",
    "            \n",
    "    return pos_dict, tar_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_list = ['act','be','have','form','high','play','report','state','sum','use']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "32000\n",
      "be\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "200\n",
      "700\n",
      "1000\n",
      "1400\n",
      "1600\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2400\n",
      "2800\n",
      "3000\n",
      "3600\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "6100\n",
      "6200\n",
      "6900\n",
      "7100\n",
      "7400\n",
      "8900\n",
      "9600\n",
      "9800\n",
      "10100\n",
      "10700\n",
      "11700\n",
      "12600\n",
      "12900\n",
      "13300\n",
      "13700\n",
      "14100\n",
      "14600\n",
      "14800\n",
      "15300\n",
      "15400\n",
      "15600\n",
      "15900\n",
      "17800\n",
      "18000\n",
      "18400\n",
      "19300\n",
      "19400\n",
      "19500\n",
      "19600\n",
      "22500\n",
      "24400\n",
      "24500\n",
      "25300\n",
      "26100\n",
      "26200\n",
      "26900\n",
      "27700\n",
      "28100\n",
      "28300\n",
      "29700\n",
      "29900\n",
      "30000\n",
      "31200\n",
      "31500\n",
      "31800\n",
      "32000\n",
      "32800\n",
      "33000\n",
      "33100\n",
      "33200\n",
      "33500\n",
      "33900\n",
      "35900\n",
      "36200\n",
      "have\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "5200\n",
      "8200\n",
      "10500\n",
      "13200\n",
      "14800\n",
      "15400\n",
      "16000\n",
      "20000\n",
      "26600\n",
      "27200\n",
      "27500\n",
      "32800\n",
      "33900\n",
      "form\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "15900\n",
      "31900\n",
      "high\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "2000\n",
      "14900\n",
      "15700\n",
      "play\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "21700\n",
      "36800\n",
      "report\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "11400\n",
      "14800\n",
      "34600\n",
      "state\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "0\n",
      "100\n",
      "400\n",
      "600\n",
      "5700\n",
      "7000\n",
      "8300\n",
      "10400\n",
      "10500\n",
      "13200\n",
      "14100\n",
      "16700\n",
      "19300\n",
      "20000\n",
      "20400\n",
      "21100\n",
      "33400\n",
      "35300\n",
      "36700\n",
      "36800\n",
      "sum\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "15600\n",
      "use\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "3500\n",
      "21300\n",
      "29100\n"
     ]
    }
   ],
   "source": [
    "for word in word_list:\n",
    "    print(word)\n",
    "    pos = find_pos(word)\n",
    "    pickle.dump(pos, open( word+\".p\", \"wb\" ) )\n",
    "    pos_dict, tar_dict = getContextEmb(pos, 3)\n",
    "    df1 = pd.DataFrame(pos_dict).transpose()\n",
    "    pickle.dump(df1, open( \"pos_\" + word + \".p\", \"wb\" ) )\n",
    "    df3 = pd.Series(tar_dict)\n",
    "    pickle.dump(df3, open( \"tar_\" + word + \".p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act\n",
      "32000\n",
      "be\n",
      "200\n",
      "700\n",
      "1000\n",
      "1400\n",
      "1600\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2400\n",
      "2800\n",
      "3000\n",
      "3600\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "6100\n",
      "6200\n",
      "6900\n",
      "7100\n",
      "7400\n",
      "8900\n",
      "9600\n",
      "9800\n",
      "10100\n",
      "10700\n",
      "11700\n",
      "12600\n",
      "12900\n",
      "13300\n",
      "13700\n",
      "14100\n",
      "14600\n",
      "14800\n",
      "15300\n",
      "15400\n",
      "15600\n",
      "15900\n",
      "17800\n",
      "18000\n",
      "18400\n",
      "19300\n",
      "19400\n",
      "19500\n",
      "19600\n",
      "22500\n",
      "24400\n",
      "24500\n",
      "25300\n",
      "26100\n",
      "26200\n",
      "26900\n",
      "27700\n",
      "28100\n",
      "28300\n",
      "29700\n",
      "29900\n",
      "30000\n",
      "31200\n",
      "31500\n",
      "31800\n",
      "32000\n",
      "32800\n",
      "33000\n",
      "33100\n",
      "33200\n",
      "33500\n",
      "33900\n",
      "35900\n",
      "36200\n",
      "have\n",
      "5200\n",
      "8200\n",
      "10500\n",
      "13200\n",
      "14800\n",
      "15400\n",
      "16000\n",
      "20000\n",
      "26600\n",
      "27200\n",
      "27500\n",
      "32800\n",
      "33900\n",
      "form\n",
      "15900\n",
      "31900\n",
      "high\n",
      "2000\n",
      "14900\n",
      "15700\n",
      "play\n",
      "21700\n",
      "36800\n",
      "report\n",
      "11400\n",
      "14800\n",
      "34600\n",
      "state\n",
      "0\n",
      "100\n",
      "400\n",
      "600\n",
      "5700\n",
      "7000\n",
      "8300\n",
      "10400\n",
      "10500\n",
      "13200\n",
      "14100\n",
      "16700\n",
      "19300\n",
      "20000\n",
      "20400\n",
      "21100\n",
      "33400\n",
      "35300\n",
      "36700\n",
      "36800\n",
      "sum\n",
      "15600\n",
      "use\n",
      "3500\n",
      "21300\n",
      "29100\n"
     ]
    }
   ],
   "source": [
    "word_list = ['act','be','have','form','high','play','report','state','sum','use']\n",
    "for word in word_list:\n",
    "    print(word)\n",
    "    pos = pickle.load(open(word+\".p\", \"rb\" ))\n",
    "    pos_dict, tar_dict = getContextEmb(pos, 2)\n",
    "    df1 = pd.DataFrame(pos_dict).transpose()\n",
    "    pickle.dump(df1, open( \"pos_\" + word + \"_2.p\", \"wb\" ) )\n",
    "    df3 = pd.Series(tar_dict)\n",
    "    pickle.dump(df3, open( \"tar_\" + word + \"_2.p\", \"wb\" ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
